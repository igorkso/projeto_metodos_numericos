{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c17a477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in ./venv/lib/python3.10/site-packages (1.1.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.10/site-packages (from scikit-surprise) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./venv/lib/python3.10/site-packages (from scikit-surprise) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.10/site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: dash in ./venv/lib/python3.10/site-packages (2.18.1)\n",
      "Requirement already satisfied: nest-asyncio in ./venv/lib/python3.10/site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: retrying in ./venv/lib/python3.10/site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: dash-table==5.0.0 in ./venv/lib/python3.10/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./venv/lib/python3.10/site-packages (from dash) (4.12.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in ./venv/lib/python3.10/site-packages (from dash) (3.0.4)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in ./venv/lib/python3.10/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.10/site-packages (from dash) (75.1.0)\n",
      "Requirement already satisfied: importlib-metadata in ./venv/lib/python3.10/site-packages (from dash) (8.5.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in ./venv/lib/python3.10/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in ./venv/lib/python3.10/site-packages (from dash) (3.0.3)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from dash) (2.32.3)\n",
      "Requirement already satisfied: plotly>=5.0.0 in ./venv/lib/python3.10/site-packages (from dash) (5.24.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./venv/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./venv/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./venv/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (1.8.2)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./venv/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./venv/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (9.0.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from plotly>=5.0.0->dash) (24.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from Werkzeug<3.1->dash) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in ./venv/lib/python3.10/site-packages (from importlib-metadata->dash) (3.20.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->dash) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->dash) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->dash) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->dash) (2.2.3)\n",
      "Requirement already satisfied: six>=1.7.0 in ./venv/lib/python3.10/site-packages (from retrying->dash) (1.16.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise # install the missing package\n",
    "!pip install dash\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76595727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7721/3486168696.py:3: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "/tmp/ipykernel_7721/3486168696.py:4: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import pandas as pd \n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0440d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/eduardo/Downloads/ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7721/3113294375.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ratings = pd.read_csv('/home/suporte/1234/ratings.csv')  # Assumindo um arquivo ratings.csv com colunas userId, movieId e rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#movies = pd.read_csv('/home/suporte/1234/movies.csv')    # Assumindo um arquivo movies.csv com colunas movieId e title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/eduardo/Downloads/ratings.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assumindo um arquivo ratings.csv com colunas userId, movieId e rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/eduardo/Downloads/movies.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/eduardo/Downloads/ratings.csv'"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('/home/suporte/1234/ratings.csv')  # Assumindo um arquivo ratings.csv com colunas userId, movieId e rating\n",
    "movies = pd.read_csv('/home/suporte/1234/movies.csv')    # Assumindo um arquivo movies.csv com colunas movieId e title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea2e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho original de ratings: (32000204, 4)\n",
      "Tamanho reduzido de ratings: (22400143, 4)\n",
      "\n",
      "Tamanho original de movies: (87585, 3)\n",
      "Tamanho reduzido de movies: (61309, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ratings = ratings.drop_duplicates()\n",
    "ratings['userId'] = ratings['userId'].astype(int)\n",
    "ratings['movieId'] = ratings['movieId'].astype(int)\n",
    "ratings['rating'] = ratings['rating'].astype(float)\n",
    "\n",
    "# Cortando 30% dos dados (mantendo 70%)\n",
    "ratings_sample = ratings.sample(frac=0.7, random_state=42)\n",
    "\n",
    "# Tratamento de dados para movies\n",
    "movies = movies.drop_duplicates()\n",
    "movies['movieId'] = movies['movieId'].astype(int)\n",
    "movies['title'] = movies['title'].astype(str)\n",
    "\n",
    "# Cortando 30% dos dados (mantendo 70%)\n",
    "movies_sample = movies.sample(frac=0.7, random_state=42)\n",
    "\n",
    "# Confirmar alterações\n",
    "print(\"Tamanho original de ratings:\", ratings.shape)\n",
    "print(\"Tamanho reduzido de ratings:\", ratings_sample.shape)\n",
    "\n",
    "print(\"\\nTamanho original de movies:\", movies.shape)\n",
    "print(\"Tamanho reduzido de movies:\", movies_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4e0eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma da matriz SVD: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Amostragem de uma fração pequena de usuários e filmes\n",
    "unique_users = ratings['userId'].drop_duplicates().sample(n=100, random_state=42)  # Limitando a 100 usuários\n",
    "unique_movies = ratings['movieId'].drop_duplicates().sample(n=100, random_state=42)  # Limitando a 100 filmes\n",
    "\n",
    "# Filtrando ratings por esses usuários e filmes amostrados\n",
    "ratings_sample = ratings[ratings['userId'].isin(unique_users) & ratings['movieId'].isin(unique_movies)]\n",
    "\n",
    "# Criando a matriz de usuários e filmes\n",
    "ratings_matrix = ratings_sample.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "\n",
    "# Aplicando SVD com 1 componente\n",
    "svd = TruncatedSVD(n_components=1, random_state=42)\n",
    "matrix_svd = svd.fit_transform(ratings_matrix)\n",
    "\n",
    "# Exibindo informações da matriz SVD\n",
    "print(\"Forma da matriz SVD:\", matrix_svd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0157a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma da matriz NMF: (20, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suporte/1234/venv/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1759: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Aplicando NMF com 1 componente\n",
    "nmf = NMF(n_components=1, random_state=42)\n",
    "matrix_nmf = nmf.fit_transform(ratings_matrix)\n",
    "\n",
    "# Exibindo informações da matriz NMF\n",
    "print(\"Forma da matriz NMF:\", matrix_nmf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9dadcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 filmes com as maiores médias de rating:\n",
      "\n",
      "Filme                                              Média de Rating\n",
      "============================================================\n",
      "$uperthief: Inside America's Biggest Bank Score (2012) 5.00\n",
      "'Tis the Season to be Merry (2021)                 5.00\n",
      "1 Message (2011)                                   5.00\n",
      "11 September Vragen (2016)                         5.00\n",
      "12 Dog Days Till Christmas (2014)                  5.00\n",
      "1500 Steps (2014)                                  5.00\n",
      "1964: Brazil Between Weapons and Books (2019)      5.00\n",
      "1984 Revolution (2011)                             5.00\n",
      "2 (2007)                                           5.00\n",
      "2 Years of Love (2016)                             5.00\n"
     ]
    }
   ],
   "source": [
    "# Supondo que você já tenha o dataframe `movies` carregado\n",
    "# Exemplo: movies = pd.read_csv('movies.csv')\n",
    "\n",
    "# Mesclando 'ratings' com 'movies' para obter o nome dos filmes\n",
    "ratings_with_titles = ratings.merge(movies[['movieId', 'title']], on='movieId')\n",
    "\n",
    "# Calculando a média dos ratings por filme (agrupando pelo nome do filme)\n",
    "average_ratings = ratings_with_titles.groupby('title')['rating'].mean()\n",
    "\n",
    "# Selecionando os 10 filmes com as maiores médias de rating\n",
    "top_movies = average_ratings.nlargest(10).reset_index()\n",
    "\n",
    "# Melhorando a saída do print (sem índice)\n",
    "print(\"Top 10 filmes com as maiores médias de rating:\\n\")\n",
    "print(\"{:<50} {:<10}\".format(\"Filme\", \"Média de Rating\"))\n",
    "print(\"=\"*60)\n",
    "for _, row in top_movies.iterrows():  # O _ ignora o índice\n",
    "    print(\"{:<50} {:.2f}\".format(row['title'], row['rating']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3618ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 filmes mais populares:\n",
      "Shawshank Redemption, The (1994): 102929 ratings\n",
      "Forrest Gump (1994): 100296 ratings\n",
      "Pulp Fiction (1994): 98409 ratings\n",
      "Matrix, The (1999): 93808 ratings\n",
      "Silence of the Lambs, The (1991): 90330 ratings\n",
      "Star Wars: Episode IV - A New Hope (1977): 85010 ratings\n",
      "Fight Club (1999): 77332 ratings\n",
      "Jurassic Park (1993): 75233 ratings\n",
      "Schindler's List (1993): 73849 ratings\n",
      "Lord of the Rings: The Fellowship of the Ring, The (2001): 73122 ratings\n"
     ]
    }
   ],
   "source": [
    "# Mesclando 'ratings' com 'movies' para obter os nomes dos filmes\n",
    "ratings_with_titles = ratings.merge(movies[['movieId', 'title']], on='movieId')\n",
    "\n",
    "# Contando o número de ratings por filme\n",
    "popularity = ratings_with_titles.groupby('title')['rating'].count()\n",
    "\n",
    "# Ordenando por popularidade (número de ratings) e exibindo os 10 mais populares\n",
    "top_popular_movies = popularity.nlargest(10)\n",
    "print(\"Top 10 filmes mais populares:\")\n",
    "for title, count in top_popular_movies.items():\n",
    "    print(f\"{title}: {count} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e3cd96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7721/2577432825.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Verifique se o filme escolhido existe no DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mchosen_movie\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Selecionando o filme escolhido\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mchosen_movie_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mchosen_movie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
     ]
    }
   ],
   "source": [
    "## Exemplo de filme escolhido\n",
    "chosen_movie = \"Toy Story (1995)\"\n",
    "\n",
    "# Verifique se o filme escolhido existe no DataFrame\n",
    "if chosen_movie in movies['title'].values:\n",
    "    # Selecionando o filme escolhido\n",
    "    chosen_movie_genres = movies.loc[movies['title'] == chosen_movie, 'genres'].values[0]\n",
    "\n",
    "    # Extraindo os gêneros do filme escolhido\n",
    "    chosen_genres = set(chosen_movie_genres.split('|'))\n",
    "\n",
    "    # Filtrando os filmes que compartilham ao menos um gênero com o filme escolhido\n",
    "    movies_with_similar_genres = movies[movies['genres'].apply(lambda x: len(set(x.split('|')).intersection(chosen_genres)) > 0)]\n",
    "\n",
    "    # Extraindo os gêneros e criando colunas binárias para cada gênero\n",
    "    genres_matrix = movies_with_similar_genres['genres'].str.get_dummies(sep='|')\n",
    "\n",
    "    # Criando uma matriz de filmes e gêneros\n",
    "    movies_genre_matrix = pd.concat([movies_with_similar_genres[['movieId']], genres_matrix], axis=1).set_index('movieId')\n",
    "\n",
    "    # Aplicando SVD com 2 componentes\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    matrix_svd = svd.fit_transform(movies_genre_matrix)\n",
    "\n",
    "    # Convertendo para DataFrame para fácil manipulação\n",
    "    svd_df = pd.DataFrame(matrix_svd, index=movies_genre_matrix.index, columns=[f'Component {i+1}' for i in range(2)])\n",
    "\n",
    "    # Exibindo a forma da matriz SVD\n",
    "    print(\"Forma da matriz SVD:\", svd_df.shape)\n",
    "\n",
    "    # Visualizando a redução de dimensionalidade\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(svd_df['Component 1'], svd_df['Component 2'], alpha=0.5)\n",
    "\n",
    "    # Destacando o filme escolhido\n",
    "    chosen_movie_id = movies.loc[movies['title'] == chosen_movie, 'movieId'].values[0]\n",
    "    plt.scatter(svd_df.loc[chosen_movie_id, 'Component 1'], svd_df.loc[chosen_movie_id, 'Component 2'], color='red', label=chosen_movie, s=100)\n",
    "\n",
    "    plt.title('Redução de Dimensionalidade com SVD (Baseado em Gêneros)')\n",
    "    plt.xlabel('Componente 1')\n",
    "    plt.ylabel('Componente 2')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"O filme '{chosen_movie}' não foi encontrado no DataFrame.\")\n",
    "\n",
    "# Função para recomendar filmes\n",
    "def recommend_movies_by_genre(movie_title, n_recommendations=5):\n",
    "    # Obter o gênero do filme escolhido\n",
    "    chosen_movie_genres = movies[movies['title'].str.contains(movie_title, case=False, na=False)]['genres'].values\n",
    "    if len(chosen_movie_genres) == 0:\n",
    "        print(f\"Erro: O filme '{movie_title}' não foi encontrado.\")\n",
    "        return pd.Series([])\n",
    "\n",
    "    chosen_movie_genres = chosen_movie_genres[0].split('|')  # Quebrar os gêneros em uma lista\n",
    "    \n",
    "    # Função auxiliar para contar gêneros em comum\n",
    "    def genre_similarity(genres):\n",
    "        movie_genres = genres.split('|')\n",
    "        return len(set(movie_genres).intersection(set(chosen_movie_genres)))\n",
    "    \n",
    "    # Adicionar uma nova coluna para contar quantos gêneros em comum os filmes têm com o escolhido\n",
    "    movies['similarity_score'] = movies['genres'].apply(genre_similarity)\n",
    "    \n",
    "    # Ordenar os filmes pela pontuação de similaridade e filtrar o filme escolhido\n",
    "    recommended_movies = movies[movies['title'] != movie_title].sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "    # Retornar os filmes mais similares\n",
    "    return recommended_movies[['title', 'genres']].head(n_recommendations)\n",
    "\n",
    "# Exemplo de recomendação\n",
    "chosen_movie2 = \"Pulp Fiction\"  # Exemplo de filme\n",
    "recommended = recommend_movies_by_genre(chosen_movie2, n_recommendations=100)\n",
    "\n",
    "# Exibindo as recomendações\n",
    "print(f\"\\nRecomendações baseadas nos gêneros de '{chosen_movie}':\")\n",
    "for idx, row in recommended.iterrows():\n",
    "    print(f\"- {row['title']} (Gêneros: {row['genres']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_movie = \"Toy Story (1995)\"\n",
    "#chosen_movie = \"11 September Vragen (2016)\"\n",
    "#chosen_movie = \"2 Years of Love (2016)\"\n",
    "\n",
    "# Verifique se o filme escolhido existe no DataFrame\n",
    "if chosen_movie in movies['title'].values:\n",
    "    # Selecionando o filme escolhido\n",
    "    chosen_movie_genres = movies.loc[movies['title'] == chosen_movie, 'genres'].values[0]\n",
    "\n",
    "    # Extraindo os gêneros do filme escolhido\n",
    "    chosen_genres = set(chosen_movie_genres.split('|'))\n",
    "\n",
    "    # Filtrando os filmes que compartilham ao menos um gênero com o filme escolhido\n",
    "    movies_with_similar_genres = movies[movies['genres'].apply(lambda x: len(set(x.split('|')).intersection(chosen_genres)) > 0)]\n",
    "\n",
    "    # Extraindo os gêneros e criando colunas binárias para cada gênero\n",
    "    genres_matrix = movies_with_similar_genres['genres'].str.get_dummies(sep='|')\n",
    "\n",
    "    # Criando uma matriz de filmes e gêneros\n",
    "    movies_genre_matrix = pd.concat([movies_with_similar_genres[['movieId']], genres_matrix], axis=1).set_index('movieId')\n",
    "\n",
    "    # Aplicando SVD com 2 componentes\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    matrix_svd = svd.fit_transform(movies_genre_matrix)\n",
    "\n",
    "    # Convertendo para DataFrame para fácil manipulação\n",
    "    svd_df = pd.DataFrame(matrix_svd, index=movies_genre_matrix.index, columns=[f'Component {i+1}' for i in range(2)])\n",
    "\n",
    "    # Exibindo a forma da matriz SVD\n",
    "    print(\"Forma da matriz SVD:\", svd_df.shape)\n",
    "\n",
    "    # Obtendo o ID do filme escolhido\n",
    "    chosen_movie_id = movies.loc[movies['title'] == chosen_movie, 'movieId'].values[0]\n",
    "\n",
    "    # Calculando as distâncias euclidianas do filme escolhido para os outros filmes\n",
    "    chosen_movie_vector = svd_df.loc[chosen_movie_id].values.reshape(1, -1)\n",
    "    distances = euclidean_distances(svd_df, chosen_movie_vector).flatten()\n",
    "\n",
    "    # Adicionando as distâncias ao DataFrame\n",
    "    svd_df['distance_to_chosen'] = distances\n",
    "\n",
    "    # Ordenando os filmes pela distância, para encontrar os mais próximos\n",
    "    closest_movies = svd_df.sort_values(by='distance_to_chosen').head(6)  # Inclui o próprio filme escolhido\n",
    "    closest_movie_ids = closest_movies.index\n",
    "\n",
    "    # Exibindo os títulos dos filmes mais próximos\n",
    "    closest_titles = movies[movies['movieId'].isin(closest_movie_ids)]\n",
    "    print(\"Filmes mais próximos do escolhido:\")\n",
    "    print(closest_titles[['title', 'genres']])\n",
    "\n",
    "    # Visualizando a redução de dimensionalidade\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(svd_df['Component 1'], svd_df['Component 2'], alpha=0.5)\n",
    "\n",
    "    # Destacando o filme escolhido\n",
    "    plt.scatter(svd_df.loc[chosen_movie_id, 'Component 1'], svd_df.loc[chosen_movie_id, 'Component 2'], color='red', label=chosen_movie, s=100)\n",
    "\n",
    "    # Destacando os filmes mais próximos (excluindo o próprio filme escolhido)\n",
    "    for movie_id in closest_movie_ids:\n",
    "        if movie_id != chosen_movie_id:\n",
    "            plt.scatter(svd_df.loc[movie_id, 'Component 1'], svd_df.loc[movie_id, 'Component 2'], color='blue', label=movies.loc[movies['movieId'] == movie_id, 'title'].values[0])\n",
    "\n",
    "    plt.title('Redução de Dimensionalidade com SVD (Baseado em Gêneros)')\n",
    "    plt.xlabel('Componente 1')\n",
    "    plt.ylabel('Componente 2')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"O filme '{chosen_movie}' não foi encontrado no DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
